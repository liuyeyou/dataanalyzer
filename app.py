import streamlit as st
import pandas as pd
import pandasai as pai
import os
from pandasai_openai import OpenAI, AzureOpenAI
from pandasai_litellm import LiteLLM

# è®¾ç½® pandas æ˜¾ç¤ºæ‰€æœ‰åˆ—ï¼Œé˜²æ­¢æ•°æ®è¢«æˆªæ–­
pd.set_option('display.max_columns', None)

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="LLM æ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹ v0.3(pandas-ai)", 
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- æ³¨å…¥è‡ªå®šä¹‰ CSS ---
hide_streamlit_style = """
<style>
/* éšè—ä¸»èœå•å’Œé¡µè„š */
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
.stDeployButton {display: none;}

/* éšè— Streamlit å¤´éƒ¨ç™½æ¡ */
[data-testid="stHeader"] {
    display: none;
}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.subheader("è®¾ç½®")
    llm_option = st.selectbox("é€‰æ‹©è¯­è¨€æ¨¡å‹", ["GPT-4o", "Gemini", "Deepseek"], index=0)
    st.divider()
    st.subheader("åŠ è½½æ•°æ®")
    uploaded_file = st.file_uploader("é€‰æ‹© CSV æ•°æ®æ–‡ä»¶", type="csv")

# --- ä¸»ä½“å†…å®¹ ---
st.title("LLM æ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹ v0.3 (pandas-ai)")

# åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ˜¾ç¤ºæ•°æ®æ ·æœ¬ï¼Œç¡®ä¿å®ƒæ€»æ˜¯åœ¨é¡¶éƒ¨
data_container = st.container()

# åˆå§‹åŒ–æˆ–æ˜¾ç¤ºèŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if uploaded_file is not None:
    # ä½¿ç”¨ pandas è¯»å– CSV
    df = pd.read_csv(uploaded_file)
    
    # åœ¨é¡¶éƒ¨çš„å®¹å™¨ä¸­æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
    with data_container:
        st.success(f'æ•°æ®æ–‡ä»¶ "{uploaded_file.name}" åŠ è½½æˆåŠŸã€‚')
        st.write("æ•°æ®æ ·æœ¬:", df.head())
        st.divider()

    # LLMé…ç½®
    if llm_option == "GPT-4o":
        api_key = os.getenv("AZURE_OPENAI_KEY")
        api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
        if not api_key or not api_base:
            st.error("è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® AZURE_OPENAI_KEY å’Œ AZURE_OPENAI_ENDPOINT")
            st.stop()
        llm = AzureOpenAI(
            deployment_name="deploy_gpt4o", # å‡è®¾æ‚¨çš„ Azure éƒ¨ç½²åç§°ä¸º deploy_gpt4o
            azure_endpoint=api_base,
            api_token=api_key,
            api_version="2024-02-01" # ä½¿ç”¨ä¸€ä¸ªè¾ƒæ–°çš„ç¨³å®š API ç‰ˆæœ¬
        )
    elif llm_option == "Gemini":
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            st.error("è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® GOOGLE_API_KEY")
            st.stop()
        os.environ["GEMINI_API_KEY"] = api_key # LiteLLM aoturead
        llm = LiteLLM(model="gemini/gemini-1.5-pro-latest")
    elif llm_option == "Deepseek":
        api_key = os.getenv("DEEPSEEK_API_KEY")
        api_base = os.getenv("DEEPSEEK_API_URL")
        if not api_key or not api_base:
            st.error("è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® DEEPSEEK_API_KEY å’Œ DEEPSEEK_API_URL")
            st.stop()
        llm = OpenAI(api_token=api_key, api_base=api_base, model="deepseek-chat", is_chat_model=True)
    else:
        st.error("æœªçŸ¥æ¨¡å‹ç±»å‹")
        st.stop()
        
    # æé—®
    question = st.chat_input("è¾“å…¥ä½ å…³äºæ•°æ®çš„é—®é¢˜...")
    if question:
        # æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
        with st.chat_message("user"):
            st.markdown(question)
        # è®°å½•ç”¨æˆ·é—®é¢˜
        st.session_state.messages.append({"role": "user", "content": question})

        with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
            try:
                # ä½¿ç”¨ v3 Agent, å…ˆå°† pandas.DataFrame åŒ…è£…æˆ pandasai.DataFrame
                pai_df = pai.DataFrame(df)
                # æ„å»ºæŒ‡ä»¤ Prompt
                system_prompt = """

                ä½ ç°åœ¨æ˜¯ä¸€åä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œé¢å‰æ˜¯ä¸€æ•´ä»½å·²åŠ è½½å®Œæ•´çš„æ•°æ®è¡¨æ ¼ï¼ˆDataFrameï¼‰ï¼Œè¯·ä¸¥æ ¼ä¾æ®æ­¤è¡¨æ ¼ä½œç­”ï¼Œä¸å¾—å‡è®¾æ•°æ®ä¸å®Œæ•´æˆ–ä½¿ç”¨ä»»ä½•è™šæ„ä¿¡æ¯ã€‚
                è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¾“å‡ºç»“æ„ï¼š

                ğŸ“Šã€æ•°æ®ç®€è¿°ã€‘

                - æ¶‰åŠçš„å­—æ®µæœ‰å“ªäº›ï¼Ÿæ•°æ®æ€»å…±æœ‰å¤šå°‘å¤©ï¼Ÿæ¶‰åŠå“ªäº›å…³é”®æ”¶å…¥é¡¹ï¼Ÿ
                - å½“å‰é—®é¢˜å…³æ³¨çš„æ—¶é—´åŒºé—´æ˜¯å“ªå‡ å¤©ï¼Ÿ

                ğŸ“‰ã€æ•°å€¼åˆ†æã€‘

                - æä¾›å…³é”®å­—æ®µçš„å¯¹æ¯”æ•°æ®ï¼ˆåŒ…æ‹¬ç»å¯¹å€¼ã€å·®å€¼ã€å˜åŒ–ç‡ï¼‰
                - ç”¨ç®€æ´æ¡ç›®åˆ—å‡ºæ¯ä¸€é¡¹å˜åŒ–ï¼Œä¿ç•™2ä½å°æ•°

                ğŸ”ã€è¶‹åŠ¿ä¸å¼‚å¸¸ã€‘

                - æŒ‡å‡ºè¶‹åŠ¿å˜åŒ–ï¼ˆå¢é•¿ã€ä¸‹é™ã€éœ‡è¡ï¼‰
                - è¯†åˆ«å¼‚å¸¸ç‚¹ï¼ˆéª¤å‡/éª¤é™ã€ç¼ºå¤±å€¼ã€è¾¹ç¼˜å€¼ç­‰ï¼‰

                ğŸ“Œã€åŸå› æ¨æµ‹ã€‘

                - ç»™å‡ºå¯èƒ½å¯¼è‡´ç°è±¡çš„ä¸šåŠ¡/æ•°æ®åŸå› 
                - é¿å…ä¸»è§‚çŒœæµ‹ï¼Œéœ€åŸºäºæ•°æ®åˆç†åˆ†æ


                ğŸ“¢ã€å»ºè®®ä¸è¡ŒåŠ¨ã€‘

                - æå‡ºåŸºäºåˆ†æç»“æœçš„ä¸šåŠ¡å»ºè®®ã€æ”¹è¿›æ–¹å‘æˆ–åç»­éªŒè¯æ–¹æ³•

                è¯·æ‰§è¡Œå¦‚ä¸‹è¦æ±‚ï¼š
                1. è¯·ç”¨ä¸­æ–‡ä½œç­”ï¼Œé€»è¾‘æ¸…æ™°ï¼Œè¯­è¨€ä¸“ä¸šï¼Œç¦æ­¢ä½¿ç”¨â€œæˆ‘è®¤ä¸ºâ€ã€â€œå¯èƒ½æ˜¯å› ä¸ºâ€è¿™ç±»æ¨¡ç³Šè¡¨è¾¾ã€‚
                2. ç¦æ­¢è¯»å–å¤–éƒ¨æ–‡ä»¶æˆ–è¿›è¡Œä»»ä½•å½¢å¼çš„æ•°æ®å‡è®¾ã€‚
                """
                # åˆå§‹åŒ– PandasAI Agent
                agent = pai.Agent(pai_df, config={
                    "llm": llm,
                    "enable_cache": False,
                    "verbose": True,
                    "conversational": False,
                    "use_sql": False, # ç¦ç”¨ SQL æŸ¥è¯¢ä»¥é¿å…å†…éƒ¨ bug
                })

                final_prompt = f"{system_prompt}\næˆ‘çš„é—®é¢˜æ˜¯ï¼š{question}"

                # è·å–å›ç­”
                answer = agent.chat(final_prompt)

                # æ˜¾ç¤ºAIå›ç­”
                with st.chat_message("assistant"):
                    st.markdown(answer)
                # è®°å½•AIå›ç­”
                st.session_state.messages.append({"role": "assistant", "content": answer})

            except Exception as e:
                st.error("AI åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–é—®é¢˜å†…å®¹ã€‚")
                st.exception(e)  # æ›´ç›´è§‚æ˜¾ç¤ºå®Œæ•´æŠ¥é”™ä¿¡æ¯
                st.stop()
else:
    st.info("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ ä¸€ä¸ª CSV æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
