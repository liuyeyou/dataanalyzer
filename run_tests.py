import os
import pandas as pd
from dotenv import load_dotenv

from pandasai.core.response.chart import ChartResponse
from pandasai.core.response.dataframe import DataFrameResponse
from pandasai.core.prompts.base import BasePrompt

# Load environment variables from .env file
load_dotenv()

# Ensure the correct backend is set for matplotlib before any other imports
import matplotlib
matplotlib.use("Agg")

from src.llm_config import configure_llm
from src.intent_detector import get_intents
from src.agent_handler import create_extraction_agent, chat_with_agent
from src.prompts import ANALYSIS_PROMPT_TEMPLATE, GUIDANCE_PROMPT_TEMPLATE, SIMPLIFICATION_PROMPT_TEMPLATE

def clean_column_names(df):
    """Cleans dataframe column names."""
    df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')
    return df

def run_analysis_pipeline(df: pd.DataFrame, question: str, llm_option: str = "GPT-4o"):
    """
    Runs the full analysis pipeline for a given dataframe and question.
    This function is a non-Streamlit adaptation of the logic in app.py.
    """
    print("---" * 20)
    print(f"ğŸš€ Starting Analysis for Question: {question}")
    print("---" * 20)

    try:
        llm = configure_llm(llm_option)
        
        # --- Step 1: Intent Detection ---
        print("\nStep 1: è¯†åˆ«ç”¨æˆ·æ„å›¾...")
        intents = get_intents(question)
        print(f"ğŸ¤– å·²è¯†åˆ«æ„å›¾: {', '.join(intents)}")
        
        # --- Step 2: Simplify Query for Data Extraction ---
        print("\nStep 2: ç®€åŒ–ç”¨æˆ·é—®é¢˜ç”¨äºæ•°æ®æå–...")
        simplification_prompt_str = SIMPLIFICATION_PROMPT_TEMPLATE.format(question=question)
        prompt_obj = BasePrompt()
        prompt_obj._resolved_prompt = simplification_prompt_str
        simplified_question = llm.call(prompt_obj)
        print("ğŸ“ ç®€åŒ–åçš„æå–é—®é¢˜:")
        print(simplified_question)

        # --- Step 3: PandasAI Agent for Data Extraction ---
        print("\nStep 3: ä½¿ç”¨ PandasAI Agent æå–åˆ†ææ‰€éœ€æ•°æ®...")
        extraction_agent = create_extraction_agent(df, llm)
        extracted_data_response = chat_with_agent(extraction_agent, simplified_question)
        
        # --- Step 4: Response Handling ---
        print("\nStep 4: å¤„ç†å“åº”å¹¶ç”Ÿæˆæœ€ç»ˆç»“æœ...")
        
        if isinstance(extracted_data_response, DataFrameResponse):
            extracted_df = extracted_data_response.value
            print("ğŸ“Š æå–çš„æ•°æ® (å‰5è¡Œ):")
            print(extracted_df.head())
            
            if extracted_df.empty:
                print("âš ï¸ æ•°æ®æå–æ­¥éª¤æœªèƒ½æ‰¾åˆ°ç›¸å…³æ•°æ®ã€‚")
                return

            if "string" in intents:
                print("\n  -> 'string' æ„å›¾æ£€æµ‹åˆ°ï¼Œå¼€å§‹æ–‡æœ¬åˆ†æ...")
                # --- Step 4a: Generate Dynamic Analysis Guidance ---
                print("\n    Step 4a: ç”ŸæˆåŠ¨æ€åˆ†ææŒ‡å¯¼...")
                data_sample_csv = extracted_df.head().to_csv(index=False)
                prompt_for_guidance = GUIDANCE_PROMPT_TEMPLATE.format(
                    question=question,
                    data_sample=data_sample_csv
                )
                guidance_prompt_obj = BasePrompt()
                guidance_prompt_obj._resolved_prompt = prompt_for_guidance
                analysis_guidance = llm.call(guidance_prompt_obj)
                print("    ğŸ“– ç”Ÿæˆçš„åˆ†ææŒ‡å¯¼:")
                print(analysis_guidance)

                # --- Step 4b: Generate Final Report using Guidance ---
                print("\n    Step 4b: ä½¿ç”¨åŠ¨æ€æŒ‡å¯¼ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š...")
                data_csv = extracted_df.to_csv(index=False)
                final_prompt_str = ANALYSIS_PROMPT_TEMPLATE.format(
                    query=question,
                    guidance=analysis_guidance,
                    data=data_csv
                )
                prompt_obj = BasePrompt()
                prompt_obj._resolved_prompt = final_prompt_str
                analysis_report = llm.call(prompt_obj)
                
                print("\n" + "---" * 10 + " FINAL REPORT " + "---" * 10)
                print(analysis_report)
                print("---" * 22)

        elif isinstance(extracted_data_response, ChartResponse):
            chart_path = extracted_data_response.value
            print(f"\nğŸ“ˆ å›¾è¡¨å·²ç”Ÿæˆå¹¶ä¿å­˜äº: {chart_path}")

        else:
            print(f"âŒ æ•°æ®æå–å¤±è´¥æˆ–è¿”å›äº†ä¸æ”¯æŒçš„å“åº”ç±»å‹: {type(extracted_data_response)}")
            print(extracted_data_response)

    except Exception as e:
        print(f"ğŸ’¥ åˆ†ææµç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    """Main function to run all test cases."""
    
    # --- Test cases for 'å˜ç°ç¾¤å°æœºå™¨äººæ”¶å…¥æ•°æ®.csv' ---
    csv_path_1 = "data/å˜ç°ç¾¤å°æœºå™¨äººæ”¶å…¥æ•°æ®.csv"
    print(f"\n\n{'='*25}\n è¿è¡Œæ–‡ä»¶: {csv_path_1} \n{'='*25}")
    try:
        df1 = pd.read_csv(csv_path_1)
        df1 = clean_column_names(df1)
        
        test_cases_1 = [
            "è®¡ç®—ä¸‹ 3åˆ°6æœˆæ¯ä¸ªæœˆçš„æœˆå‡æ€»æ”¶å…¥",
            "è¯·ç”»å‡º2025å¹´3æœˆåˆ°6æœˆæœˆå‡æ€»æ”¶å…¥çš„æŠ˜çº¿å›¾",
            "åˆ†æä¸‹ä¸ºä»€ä¹ˆ20250601æ”¶å…¥æ¯”20250501æ”¶å…¥ä½ï¼Ÿä»å¤šä¸ªè§’åº¦åˆ†æ å› ä¸ºæ•°æ®é‡Œæœ‰å„ä¸ªå˜ç°åœºæ™¯çš„æ•°æ®"
        ]
        
        for i, case in enumerate(test_cases_1, 1):
            run_analysis_pipeline(df1, case)

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {csv_path_1}")
    except Exception as e:
        print(f"å¤„ç† {csv_path_1} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # --- Test cases for 'å……å€¼æ•°æ®.csv' ---
    csv_path_2 = "data/å……å€¼æ•°æ®.csv"
    print(f"\n\n{'='*25}\n è¿è¡Œæ–‡ä»¶: {csv_path_2} \n{'='*25}")
    try:
        df2 = pd.read_csv(csv_path_2)
        df2 = clean_column_names(df2)
        
        test_cases_2 = [
            "é‚£2025å¹´6æœˆ1æ—¥æ¯”5æœˆ1æ—¥æ”¶å…¥ä¸‹é™ï¼Œä¸»è¦å—åˆ°å……å€¼äººæ•°å‡å°‘çš„å½±å“è¿˜æ˜¯å—åˆ°å……å€¼arpuå€¼çš„å½±å“ï¼Ÿå¦‚æœå……å€¼äººæ•°å‡å°‘çš„åŸå› æ˜¯ä»€ä¹ˆï¼Œå’ŒDAUå‡å°‘æœ‰å…³ç³»å—ï¼Ÿè¿˜æ˜¯å……å€¼ç‡é™ä½äº†å‘¢ï¼ŸåŒç†ï¼Œarpuå€¼ä¹Ÿæ˜¯ä¸€æ ·çš„æ¨ç†ï¼Œéº»çƒ¦ç»™æˆ‘ä¸€ä¸ªç»¼åˆçš„åˆ†æåˆ¤æ–­ã€‚",
            "åˆ†æ2025å¹´1æœˆè‡³5æœˆå¯¹æ¯”2024å¹´çš„1æœˆè‡³5æœˆï¼Œå„å­—æ®µæŒ‰æœˆæ±‚æ¯ä¸ªæœˆçš„æ—¥å¹³å‡å€¼ï¼Œæ ¹æ®æ¯ä¸ªæœˆçš„æ—¥å¹³å‡å€¼åŒæ¯”2024å¹´ï¼Œç»™å‡ºåˆ†æç»“è®º",
            "å“ªå¤©æ”¶å…¥æœ€é«˜ æ”¶å…¥æ˜¯å¤šå°‘"
        ]

        for i, case in enumerate(test_cases_2, 1):
            run_analysis_pipeline(df2, case)
            
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {csv_path_2}")
    except Exception as e:
        print(f"å¤„ç† {csv_path_2} æ—¶å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main() 